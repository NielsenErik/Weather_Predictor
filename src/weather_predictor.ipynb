{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel():\n",
    "    def __init__(self, df, classifier = 'Knn', oversample = False) -> None:\n",
    "        self.classifier = classifier\n",
    "        self.df = df\n",
    "        self.oversample = oversample\n",
    "        if self.oversample:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.oversampled_split_df()\n",
    "        else:\n",
    "            self.X_train, self.X_test, self.y_train, self.y_test = self.split_df()\n",
    "        self.model_types = ['Knn', 'SVM', 'LogisticRegression', 'DecisionTreeClassifier', 'GaussianNB', 'RandomForestClassifier']\n",
    "\n",
    "    def model_knn(self, X_train, y_train, X_test, y_test):\n",
    "        print('Model Knn')\n",
    "        knn = KNeighborsClassifier(n_neighbors=5)\n",
    "        model = knn.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def model_svm(self, X_train, y_train, X_test, y_test):\n",
    "        print('Model SVM')\n",
    "        svc = SVC()\n",
    "        model = svc.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "    def model_logistic_regression(self, X_train, y_train, X_test, y_test):\n",
    "        print('Model LogisticRegression')\n",
    "        lr = LogisticRegression()\n",
    "        model = lr.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def model_decision_tree(self, X_train, y_train, X_test, y_test):\n",
    "        print('Model DecisionTreeClassifier')\n",
    "        dt = DecisionTreeClassifier()\n",
    "        model = dt.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def model_gaussian_nb(self, X_train, y_train, X_test, y_test):\n",
    "        print('Model GaussianNB')\n",
    "        gnb = GaussianNB()\n",
    "        model = gnb.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def model_random_forest(self, X_train, y_train, X_test, y_test):\n",
    "        print('Model RandomForestClassifier')\n",
    "        rf = RandomForestClassifier(n_estimators=10, random_state=0, max_depth=2, class_weight='balanced')\n",
    "        model = rf.fit(X_train, y_train)\n",
    "        return model\n",
    "\n",
    "    def select_model(self, X_train, y_train, X_test, y_test):\n",
    "        if self.classifier == 'Knn':\n",
    "            model = self.model_knn(X_train, y_train, X_test, y_test)\n",
    "        elif self.classifier == 'SVM':\n",
    "            model = self.model_svm(X_train, y_train, X_test, y_test)\n",
    "        elif self.classifier == 'LogisticRegression':\n",
    "            model = self.model_logistic_regression(X_train, y_train, X_test, y_test)\n",
    "        elif self.classifier == 'DecisionTreeClassifier':\n",
    "            model = self.model_decision_tree(X_train, y_train, X_test, y_test)\n",
    "        elif self.classifier == 'GaussianNB':\n",
    "            model = self.model_gaussian_nb(X_train, y_train, X_test, y_test)\n",
    "        elif self.classifier == 'RandomForestClassifier':\n",
    "            model = self.model_random_forest(X_train, y_train, X_test, y_test)\n",
    "        else:\n",
    "            print('Model not found')\n",
    "        return model\n",
    "\n",
    "    def predict(self, model, X_test):\n",
    "        y_pred = model.predict(X_test)\n",
    "        return y_pred\n",
    "\n",
    "    def evaluate(self, y_test, y_pred):\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        print(f'Confusion Matrix: \\n {conf_matrix} \\n')\n",
    "        print(f'Classification Report: \\n {class_report} \\n')\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "\n",
    "        return accuracy\n",
    "\n",
    "    def split_df(self):\n",
    "        y = self.df['Rain_Tomorrow_Num']\n",
    "        X = self.df.drop(['Rain_Tomorrow_Num'], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def oversampled_split_df(self):\n",
    "        sm = SMOTE(sampling_strategy = 'minority', random_state = 34)\n",
    "        y = self.df['Rain_Tomorrow_Num']\n",
    "        X = self.df.drop(['Rain_Tomorrow_Num'], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    def run(self):\n",
    "        model = self.select_model(self.X_train, self.y_train, self.X_test, self.y_test)\n",
    "        y_pred = self.predict(model, self.X_test)\n",
    "        self.evaluate(self.y_test, y_pred)\n",
    "\n",
    "    def run_all_models(self):\n",
    "        for model in self.model_types:\n",
    "            self.classifier = model\n",
    "            self.run()\n",
    "            print('---------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalanceClasses():\n",
    "    def __init__(self, df, n_classes = 2) -> None:\n",
    "        self.df = df\n",
    "        self.n_classes = n_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/weather_cleaned_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Knn\n",
      "Confusion Matrix: \n",
      " [[28954   587]\n",
      " [ 3649   578]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93     29541\n",
      "           1       0.50      0.14      0.21      4227\n",
      "\n",
      "    accuracy                           0.87     33768\n",
      "   macro avg       0.69      0.56      0.57     33768\n",
      "weighted avg       0.84      0.87      0.84     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.8745557924662403\n",
      "---------------------------\n",
      "Model SVM\n",
      "Confusion Matrix: \n",
      " [[29541     0]\n",
      " [ 4227     0]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93     29541\n",
      "           1       0.00      0.00      0.00      4227\n",
      "\n",
      "    accuracy                           0.87     33768\n",
      "   macro avg       0.44      0.50      0.47     33768\n",
      "weighted avg       0.77      0.87      0.82     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.874822316986496\n",
      "---------------------------\n",
      "Model LogisticRegression\n",
      "Confusion Matrix: \n",
      " [[29215   326]\n",
      " [ 3715   512]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     29541\n",
      "           1       0.61      0.12      0.20      4227\n",
      "\n",
      "    accuracy                           0.88     33768\n",
      "   macro avg       0.75      0.56      0.57     33768\n",
      "weighted avg       0.85      0.88      0.84     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.8803304904051172\n",
      "---------------------------\n",
      "Model DecisionTreeClassifier\n",
      "Confusion Matrix: \n",
      " [[26602  2939]\n",
      " [ 2666  1561]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90     29541\n",
      "           1       0.35      0.37      0.36      4227\n",
      "\n",
      "    accuracy                           0.83     33768\n",
      "   macro avg       0.63      0.63      0.63     33768\n",
      "weighted avg       0.84      0.83      0.84     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.834014451551765\n",
      "---------------------------\n",
      "Model GaussianNB\n",
      "Confusion Matrix: \n",
      " [[27500  2041]\n",
      " [ 2531  1696]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.92     29541\n",
      "           1       0.45      0.40      0.43      4227\n",
      "\n",
      "    accuracy                           0.86     33768\n",
      "   macro avg       0.68      0.67      0.67     33768\n",
      "weighted avg       0.86      0.86      0.86     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.8646055437100213\n",
      "---------------------------\n",
      "Model RandomForestClassifier\n",
      "Confusion Matrix: \n",
      " [[20949  8592]\n",
      " [ 1253  2974]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.71      0.81     29541\n",
      "           1       0.26      0.70      0.38      4227\n",
      "\n",
      "    accuracy                           0.71     33768\n",
      "   macro avg       0.60      0.71      0.59     33768\n",
      "weighted avg       0.86      0.71      0.76     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.7084517886756693\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "predictor = BaselineModel(df, classifier='Knn')\n",
    "predictor.run_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Knn\n",
      "Confusion Matrix: \n",
      " [[22824  6729]\n",
      " [ 1779  2436]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.77      0.84     29553\n",
      "           1       0.27      0.58      0.36      4215\n",
      "\n",
      "    accuracy                           0.75     33768\n",
      "   macro avg       0.60      0.68      0.60     33768\n",
      "weighted avg       0.85      0.75      0.78     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.748045486851457\n",
      "---------------------------\n",
      "Model SVM\n",
      "Confusion Matrix: \n",
      " [[ 5343 24210]\n",
      " [  447  3768]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.18      0.30     29553\n",
      "           1       0.13      0.89      0.23      4215\n",
      "\n",
      "    accuracy                           0.27     33768\n",
      "   macro avg       0.53      0.54      0.27     33768\n",
      "weighted avg       0.82      0.27      0.29     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.26981165600568585\n",
      "---------------------------\n",
      "Model LogisticRegression\n",
      "Confusion Matrix: \n",
      " [[21160  8393]\n",
      " [ 1283  2932]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.72      0.81     29553\n",
      "           1       0.26      0.70      0.38      4215\n",
      "\n",
      "    accuracy                           0.71     33768\n",
      "   macro avg       0.60      0.71      0.60     33768\n",
      "weighted avg       0.86      0.71      0.76     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.7134565268893627\n",
      "---------------------------\n",
      "Model DecisionTreeClassifier\n",
      "Confusion Matrix: \n",
      " [[25155  4398]\n",
      " [ 2302  1913]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88     29553\n",
      "           1       0.30      0.45      0.36      4215\n",
      "\n",
      "    accuracy                           0.80     33768\n",
      "   macro avg       0.61      0.65      0.62     33768\n",
      "weighted avg       0.84      0.80      0.82     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.8015873015873016\n",
      "---------------------------\n",
      "Model GaussianNB\n",
      "Confusion Matrix: \n",
      " [[22534  7019]\n",
      " [ 1335  2880]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84     29553\n",
      "           1       0.29      0.68      0.41      4215\n",
      "\n",
      "    accuracy                           0.75     33768\n",
      "   macro avg       0.62      0.72      0.63     33768\n",
      "weighted avg       0.86      0.75      0.79     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.7526060175313907\n",
      "---------------------------\n",
      "Model RandomForestClassifier\n",
      "Confusion Matrix: \n",
      " [[20792  8761]\n",
      " [ 1196  3019]] \n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.70      0.81     29553\n",
      "           1       0.26      0.72      0.38      4215\n",
      "\n",
      "    accuracy                           0.71     33768\n",
      "   macro avg       0.60      0.71      0.59     33768\n",
      "weighted avg       0.86      0.71      0.75     33768\n",
      " \n",
      "\n",
      "Accuracy: 0.705135039090263\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "oversapled_predictor = BaselineModel(df, classifier='Knn', oversample=True)\n",
    "oversapled_predictor.run_all_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
